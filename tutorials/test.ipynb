{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f3280e-00ad-4c52-941c-71c1e718b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from data_loader import get_loader\n",
    "from models_4 import VqaModel, SANModel\n",
    "import warnings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41721781-fcf1-489f-a2b7-de4d0d2a1592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_str_list(fname):\n",
    "    with open(fname) as f:\n",
    "        lines = f.readlines()\n",
    "    lines = [l.strip() for l in lines]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485240ce-985d-4aa8-a517-db302ca43532",
   "metadata": {},
   "outputs": [],
   "source": [
    "qst_vocab = load_str_list(\"datasets/vocab_questions.txt\")\n",
    "ans_vocab = load_str_list(\"datasets/vocab_answers.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f9d82f-5336-48b0-a819-90586660bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx_dict = {w:n_w for n_w, w in enumerate(qst_vocab)}\n",
    "unk2idx = word2idx_dict['<unk>'] if '<unk>' in word2idx_dict else None\n",
    "vocab_size = len(qst_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f32e498-92f2-4bef-937a-99d2b0742e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2idx(w):\n",
    "    if w in word2idx_dict:\n",
    "        return word2idx_dict[w]\n",
    "    elif unk2idx is not None:\n",
    "         return unk2idx\n",
    " \n",
    "    else:\n",
    "        raise ValueError('word %s not in dictionary (while dictionary does not contain <unk>)' % w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7ebd3b-b581-47e0-ae78-1bc0bb3cfdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path, transform=None):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = image.resize([224, 224], Image.LANCZOS)\n",
    "    \n",
    "    if transform is not None:\n",
    "        image = transform(image).unsqueeze(0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd9bf3e-3ba3-4cbf-9b46-025169bb107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeAttention(model, img, layer):\n",
    "    \n",
    "    pi = model.attn_features[layer].squeeze()\n",
    "    print(pi.size())\n",
    "    \n",
    "    pi = pi.view(14,14)\n",
    "    attn = m(pi)\n",
    "    \n",
    "    image = image.squeeze(0)\n",
    "    img = torch.numpy(img)\n",
    "    attn  = torch.numpy(attn)\n",
    "    \n",
    "#     print(image.shape, attn.shape)\n",
    "    ## Visualization yet to be completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f2d399-b331-4bde-8c70-9103532275b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir='./datasets\n",
    "log_dir='./logs'\n",
    "model_dir='./models'\n",
    "\n",
    "max_qst_length=30\n",
    "max_num_ans=10\n",
    "embed_size=1024\n",
    "word_embed_size=300\n",
    "\n",
    "num_layers=2\n",
    "hidden_size=512\n",
    "\n",
    "num_epochs=30\n",
    "batch_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c33af5-30f0-4f24-98b0-61231b01988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = get_loader(\n",
    "    input_dir=args.input_dir,\n",
    "    \n",
    "    input_vqa_train='train.npy',\n",
    "    input_vqa_valid='valid.npy',\n",
    "    \n",
    "    max_qst_length=args.max_qst_length,\n",
    "    max_num_ans=args.max_num_ans,\n",
    "    \n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=args.num_workers,\n",
    "    \n",
    "    subset=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b286d160-c13b-44a6-bd4f-7866af2215a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qst_vocab_size = data_loader['train'].dataset.qst_vocab.vocab_size\n",
    "ans_vocab_size = data_loader['train'].dataset.ans_vocab.vocab_size\n",
    "ans_unk_idx = data_loader['train'].dataset.ans_vocab.unk2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33297c57-3e8a-4920-a355-2195cf67e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VqaModel(\n",
    "    embed_size=args.embed_size,\n",
    "    qst_vocab_size=qst_vocab_size,\n",
    "    ans_vocab_size=ans_vocab_size,\n",
    "    word_embed_size=args.word_embed_size,\n",
    "    num_layers=args.num_layers,\n",
    "    # hidden_size=args.hidden_size).to(device)\n",
    "    hidden_size=args.hidden_size,\n",
    "    stack_size=args.stack_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce97ecbb-b1a5-4365-ba10-5e75799d643e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbe25e2-663c-4432-81dd-9afebdfafdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e0c7c-891e-463d-ba9d-282df2dabe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(args.image_path)\n",
    "image = cv2.resize(image, dsize=(224, 224), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "image = torch.from_numpy(image).float()\n",
    "image = image.to(device)\n",
    "\n",
    "image = image.unsqueeze(dim=0)\n",
    "image = image.view(1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb4dfe9-3338-486d-9d07-ee40e0e0f3db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c83762-804a-412c-8902-050e7daa8440",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_qst_length=30\n",
    "\n",
    "question = args.question\n",
    "q_list = list(question.split(\" \"))\n",
    "#     print(q_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b96a39f-f48d-4a29-9af1-98a8ecd7885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 'valid'\n",
    "\n",
    "qst2idc = np.array([word2idx('<pad>')] * max_qst_length)  # padded with '<pad>' in 'ans_vocab'\n",
    "qst2idc[:len(q_list)] = [word2idx(w) for w in q_list]\n",
    "\n",
    "question = qst2idc\n",
    "question = torch.from_numpy(question).long()\n",
    "\n",
    "question = question.to(device)\n",
    "question = question.unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb2c01-6f83-4f06-bbde-8480d8508c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(args.saved_model)\n",
    "model = model.to(device)\n",
    "\n",
    "#torch.cuda.empty_cache()\n",
    "model.eval()\n",
    "\n",
    "output = model(image, question)\n",
    "\n",
    "#     Visualization yet to be implemented\n",
    "    if model.__class__.__name__ == \"VQAModel\":\n",
    "        print(model.attn_features[0].size())\n",
    "         visualizeAttention(model, image, layer=0)\n",
    "\n",
    "predicts = torch.softmax(output, 1)\n",
    "probs, indices = torch.topk(predicts, k=5, dim=1)\n",
    "\n",
    "probs = probs.squeeze()\n",
    "indices = indices.squeeze()\n",
    "print(\"predicted - probabilty\")\n",
    "for i in range(5):\n",
    "#         print(probs.size(), indices.size())\n",
    "#         print(ans_vocab[indices[1].item()],probs[1].item())\n",
    "    print(\"'{}' - {:.4f}\".format(ans_vocab[indices[i].item()], probs[i].item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cv]",
   "language": "python",
   "name": "conda-env-cv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
